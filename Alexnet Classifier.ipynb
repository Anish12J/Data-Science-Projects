{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81add520-f8ad-4726-acc1-d9ff8941a09b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator \n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from tensorflow.keras.metrics import Recall, Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5345defa-ce5d-4884-8b5f-f90acc5e6607",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataGen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_dataGen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9d3a5ab-5ea6-4a90-aad7-c1d3c5b5a178",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path= 'C:/Users/Lenovo/Desktop/Guvi DS/Project/Disease Classification/Data/color'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "339b9565-3ce1-4d9d-a4db-af4d45a4b2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54305 images\n",
      "Unique labels : {'Tomato___Early_blight', 'Potato___Early_blight', 'Apple___Black_rot', 'Tomato___Leaf_Mold', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Tomato___Late_blight', 'Grape___healthy', 'Cherry_(including_sour)___healthy', 'Tomato___healthy', 'Strawberry___Leaf_scorch', 'Tomato___Septoria_leaf_spot', 'Corn_(maize)___healthy', 'Tomato___Tomato_mosaic_virus', 'Grape___Esca_(Black_Measles)', 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Potato___Late_blight', 'Blueberry___healthy', 'Pepper,_bell___Bacterial_spot', 'Raspberry___healthy', 'Soybean___healthy', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Peach___Bacterial_spot', 'Peach___healthy', 'Strawberry___healthy', 'Apple___Apple_scab', 'Pepper,_bell___healthy', 'Apple___healthy', 'Cherry_(including_sour)___Powdery_mildew', 'Corn_(maize)___Northern_Leaf_Blight', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Squash___Powdery_mildew', 'Potato___healthy', 'Tomato___Bacterial_spot', 'Tomato___Target_Spot', 'Apple___Cedar_apple_rust', 'Orange___Haunglongbing_(Citrus_greening)', 'Corn_(maize)___Common_rust_', 'Grape___Black_rot'}\n",
      "Train set size: 43444\n",
      "Test set size: 10861\n"
     ]
    }
   ],
   "source": [
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "# Function to check if a file is an image\n",
    "def is_image_file(file_path):\n",
    "    try:\n",
    "        img = Image.open(file_path)\n",
    "        img.verify()\n",
    "        return True\n",
    "    except :\n",
    "        return False\n",
    "\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "        #print(f'Processing directory: {root}')\n",
    "        file_path = os.path.join(root, file)\n",
    "        if is_image_file(file_path) :\n",
    "            file_paths.append(file_path)\n",
    "            labels.append(os.path.basename(root))  \n",
    "            #print(os.path.basename(root))\n",
    "\n",
    "print(f'Found {len(file_paths)} images')\n",
    "\n",
    "print(f'Unique labels : {set(labels)}')\n",
    "\n",
    "filePath_series = pd.Series(file_paths, name='Filepaths')\n",
    "label_series = pd.Series(labels, name='Labels')\n",
    "\n",
    "df = pd.concat([filePath_series, label_series], axis=1)\n",
    "\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(file_paths, labels , test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'Train set size: {len(train_files)}')\n",
    "print(f'Test set size: {len(test_files)}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbcf8bc",
   "metadata": {},
   "source": [
    "Checking if the file is an image and the appending the path and the label to the respective arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d26fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "        #print(f'Processing directory: {root}')\n",
    "        file_path = os.path.join(root, file)\n",
    "        if is_image_file(file_path) :\n",
    "            file_paths.append(file_path)\n",
    "            labels.append(os.path.basename(root))  \n",
    "            #print(os.path.basename(root))\n",
    "\n",
    "print(f'Found {len(file_paths)} images')\n",
    "\n",
    "print(f'Unique labels : {set(labels)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ee0fbf",
   "metadata": {},
   "source": [
    "Creating a Dataframe with the images path and corresponding labels and then splitting the data into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db96a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath_series = pd.Series(file_paths, name='Filepaths')\n",
    "label_series = pd.Series(labels, name='Labels')\n",
    "\n",
    "df = pd.concat([filePath_series, label_series], axis=1)\n",
    "\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(file_paths, labels , test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'Train set size: {len(train_files)}')\n",
    "print(f'Test set size: {len(test_files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ef33cbc-5e45-4b8c-8c99-d88a7f4e3da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filepaths    43444\n",
      "Labels          38\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_filesSeries = pd.Series(train_files, name='Filepaths')\n",
    "train_labelsSeries = pd.Series(train_labels, name='Labels')\n",
    "training_df = pd.concat([train_filesSeries,train_labelsSeries], axis=1)\n",
    "training_df.head()\n",
    "print(training_df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bea1d28f-1fe0-41bf-b30a-f09da99ac2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepaths</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Users/Lenovo/Desktop/Guvi DS/Project/Diseas...</td>\n",
       "      <td>Corn_(maize)___Northern_Leaf_Blight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Users/Lenovo/Desktop/Guvi DS/Project/Diseas...</td>\n",
       "      <td>Tomato___Target_Spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Users/Lenovo/Desktop/Guvi DS/Project/Diseas...</td>\n",
       "      <td>Squash___Powdery_mildew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Users/Lenovo/Desktop/Guvi DS/Project/Diseas...</td>\n",
       "      <td>Tomato___Leaf_Mold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Users/Lenovo/Desktop/Guvi DS/Project/Diseas...</td>\n",
       "      <td>Tomato___Target_Spot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Filepaths  \\\n",
       "0  C:/Users/Lenovo/Desktop/Guvi DS/Project/Diseas...   \n",
       "1  C:/Users/Lenovo/Desktop/Guvi DS/Project/Diseas...   \n",
       "2  C:/Users/Lenovo/Desktop/Guvi DS/Project/Diseas...   \n",
       "3  C:/Users/Lenovo/Desktop/Guvi DS/Project/Diseas...   \n",
       "4  C:/Users/Lenovo/Desktop/Guvi DS/Project/Diseas...   \n",
       "\n",
       "                                Labels  \n",
       "0  Corn_(maize)___Northern_Leaf_Blight  \n",
       "1                 Tomato___Target_Spot  \n",
       "2              Squash___Powdery_mildew  \n",
       "3                   Tomato___Leaf_Mold  \n",
       "4                 Tomato___Target_Spot  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_filesSeries = pd.Series(test_files, name='Filepaths')\n",
    "test_labelsSeries = pd.Series(test_labels, name='Labels')\n",
    "testing_df = pd.concat([test_filesSeries,test_labelsSeries], axis=1)\n",
    "testing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1683e1c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m     label_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(train_dir, label)\n\u001b[0;32m     12\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(label_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 13\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(test_files, test_labels):\n\u001b[0;32m     16\u001b[0m     label_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(test_dir, label)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\shutil.py:417\u001b[0m, in \u001b[0;36mcopy\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[0;32m    416\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[1;32m--> 417\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    418\u001b[0m copymode(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\shutil.py:274\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;66;03m# Windows, see:\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;66;03m# https://github.com/python/cpython/pull/7160#discussion_r195405230\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _WINDOWS \u001b[38;5;129;01mand\u001b[39;00m file_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 274\u001b[0m     \u001b[43m_copyfileobj_readinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfsrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCOPY_BUFSIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dst\n\u001b[0;32m    277\u001b[0m copyfileobj(fsrc, fdst)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\shutil.py:178\u001b[0m, in \u001b[0;36m_copyfileobj_readinto\u001b[1;34m(fsrc, fdst, length)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(\u001b[38;5;28mbytearray\u001b[39m(length)) \u001b[38;5;28;01mas\u001b[39;00m mv:\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m         n \u001b[38;5;241m=\u001b[39m \u001b[43mfsrc_readinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n:\n\u001b[0;32m    180\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Not necessary - Only needed when we run the data for the first time to save it\n",
    "\n",
    "train_dir = 'C:/Users/Lenovo/Desktop/Guvi DS/Project/Disease Classification/Data/trainData'\n",
    "test_dir = 'C:/Users/Lenovo/Desktop/Guvi DS/Project/Disease Classification/Data/testData'\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for file, label in zip(train_files, train_labels):\n",
    "    label_dir = os.path.join(train_dir, label)\n",
    "    os.makedirs(label_dir, exist_ok=True)\n",
    "    shutil.copy(file, label_dir)\n",
    "    \n",
    "for file, label in zip(test_files, test_labels):\n",
    "    label_dir = os.path.join(test_dir, label)\n",
    "    os.makedirs(label_dir, exist_ok=True)\n",
    "    shutil.copy(file, label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b7eeff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43444 validated image filenames belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_dataGen.flow_from_dataframe(\n",
    "    dataframe=training_df,\n",
    "    x_col='Filepaths',\n",
    "    y_col='Labels',\n",
    "    target_size=(250, 250),\n",
    "    batch_size=38,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acd55a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10861 validated image filenames belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_dataGen.flow_from_dataframe(\n",
    "    dataframe=testing_df,\n",
    "    x_col = 'Filepaths',\n",
    "    y_col = 'Labels',\n",
    "    target_size = (250, 250),\n",
    "    batch_size = 38,\n",
    "    class_mode ='categorical',\n",
    "    shuffle = False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d084d99-7f05-42fb-920a-8c6e710dbced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Labels'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6019d9b6-9f61-47aa-965e-fda3252b033c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 60, 60, 96)        34944     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 30, 30, 96)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 30, 30, 96)       384       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 20, 20, 256)       2973952   \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 10, 10, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 10, 10, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 384)         885120    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 8, 8, 384)        1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 6, 384)         1327488   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 6, 6, 384)        1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 4, 4, 256)         884992    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 2, 2, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 2, 2, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              4198400   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 4096)             16384     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 4096)             16384     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 38)                155686    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 38)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,280,166\n",
      "Trainable params: 27,261,030\n",
      "Non-trainable params: 19,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(filters = 96,kernel_size = (11,11), input_shape = (250,250,3), strides = (4,4), padding = 'valid', activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2), strides = (2,2), padding = 'valid'))\n",
    "classifier.add(BatchNormalization())\n",
    "               \n",
    "classifier.add(Conv2D(filters = 256, kernel_size = (11,11), strides = (1,1), padding = 'valid', activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2), strides = (2,2), padding = 'valid'))\n",
    "classifier.add(BatchNormalization())\n",
    "               \n",
    "classifier.add(Conv2D(filters = 384, kernel_size = (3,3), strides = (1,1), padding = 'valid', activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "classifier.add(Conv2D(filters = 384, kernel_size = (3,3), strides = (1,1), padding = 'valid', activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "classifier.add(Conv2D(filters = 256, kernel_size = (3,3), strides = (1,1), padding = 'valid', activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2), strides = (2,2), padding = 'valid'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(4096, input_shape = (250*250*3, ), activation = 'relu'))\n",
    "classifier.add(Dropout(0.4))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "classifier.add(Dense(4096, activation = 'relu'))\n",
    "classifier.add(Dropout(0.4))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "classifier.add(Dense(training_df['Labels'].nunique()))\n",
    "classifier.add(Activation('softmax'))\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19279dce-eb3f-4f7d-819e-8d9d39e7cb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam' , loss = 'categorical_crossentropy', metrics = ['accuracy', Precision(name='precision'),\n",
    "        Recall(name='recall')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fdfac52-aaac-4207-83e7-139e66a02ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1144/1144 [==============================] - 1948s 2s/step - loss: 2.5103 - accuracy: 0.3893 - precision: 0.5636 - recall: 0.2888 - val_loss: 9.5393 - val_accuracy: 0.2677 - val_precision: 0.2959 - val_recall: 0.2604\n",
      "Epoch 2/10\n",
      "1144/1144 [==============================] - 1891s 2s/step - loss: 1.5508 - accuracy: 0.5728 - precision: 0.7034 - recall: 0.4831 - val_loss: 2.5643 - val_accuracy: 0.4903 - val_precision: 0.5720 - val_recall: 0.4458\n",
      "Epoch 3/10\n",
      "1144/1144 [==============================] - 30585s 27s/step - loss: 1.2262 - accuracy: 0.6533 - precision: 0.7565 - recall: 0.5796 - val_loss: 1.5844 - val_accuracy: 0.5888 - val_precision: 0.6806 - val_recall: 0.5348\n",
      "Epoch 4/10\n",
      "1144/1144 [==============================] - 1982s 2s/step - loss: 1.0540 - accuracy: 0.6948 - precision: 0.7811 - recall: 0.6282 - val_loss: 1.2781 - val_accuracy: 0.6587 - val_precision: 0.7513 - val_recall: 0.5949\n",
      "Epoch 5/10\n",
      "1144/1144 [==============================] - 1977s 2s/step - loss: 1.0325 - accuracy: 0.7090 - precision: 0.7921 - recall: 0.6467 - val_loss: 0.9528 - val_accuracy: 0.7353 - val_precision: 0.7951 - val_recall: 0.6933\n",
      "Epoch 6/10\n",
      "1144/1144 [==============================] - 1927s 2s/step - loss: 1.0274 - accuracy: 0.7167 - precision: 0.7864 - recall: 0.6645 - val_loss: 7.7964 - val_accuracy: 0.6610 - val_precision: 0.7265 - val_recall: 0.6199\n",
      "Epoch 7/10\n",
      "1144/1144 [==============================] - 2767s 2s/step - loss: 0.9311 - accuracy: 0.7326 - precision: 0.7988 - recall: 0.6825 - val_loss: 4.1018 - val_accuracy: 0.4722 - val_precision: 0.5293 - val_recall: 0.4409\n",
      "Epoch 8/10\n",
      "1144/1144 [==============================] - 3515s 3s/step - loss: 0.8463 - accuracy: 0.7548 - precision: 0.8173 - recall: 0.7064 - val_loss: 9.6822 - val_accuracy: 0.3076 - val_precision: 0.3189 - val_recall: 0.3025\n",
      "Epoch 9/10\n",
      "1144/1144 [==============================] - 1985s 2s/step - loss: 0.8821 - accuracy: 0.7506 - precision: 0.8153 - recall: 0.6994 - val_loss: 2.7513 - val_accuracy: 0.5434 - val_precision: 0.6033 - val_recall: 0.5046\n",
      "Epoch 10/10\n",
      "1144/1144 [==============================] - 1967s 2s/step - loss: 0.9040 - accuracy: 0.7395 - precision: 0.8099 - recall: 0.6852 - val_loss: 0.8618 - val_accuracy: 0.8059 - val_precision: 0.8539 - val_recall: 0.7666\n"
     ]
    }
   ],
   "source": [
    "final_model = classifier.fit(train_generator,validation_data= test_generator,epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f12f458e-2e93-48e2-a633-c2115bfebad2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier.save(\"C:/Users/Lenovo/Desktop/Guvi DS/Project/Disease Classification/AlexNetModel.hdf5\")\n",
    "classifier.save(\"AlexNetModel.hdf5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
